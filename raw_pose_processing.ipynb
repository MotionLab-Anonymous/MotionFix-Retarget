{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Poses from Amass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "# Choose the device to run the body model on.\n",
    "comp_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "\n",
    "male_bm_path = './body_models/smplh/male/model.npz'\n",
    "male_dmpl_path = './body_models/dmpls/male/model.npz'\n",
    "\n",
    "female_bm_path = './body_models/smplh/female/model.npz'\n",
    "female_dmpl_path = './body_models/dmpls/female/model.npz'\n",
    "\n",
    "neutral_bm_path = './body_models/smplh/neutral/model.npz'\n",
    "neutral_dmpl_path = './body_models/dmpls/neutral/model.npz'\n",
    "\n",
    "num_betas = 10 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "\n",
    "male_bm = BodyModel(bm_fname=male_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=male_dmpl_path).to(comp_device)\n",
    "faces = c2c(male_bm.f)\n",
    "\n",
    "female_bm = BodyModel(bm_fname=female_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=female_dmpl_path).to(comp_device)\n",
    "\n",
    "neutral_bm = BodyModel(bm_fname=neutral_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=neutral_dmpl_path).to(comp_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "folders = []\n",
    "dataset_names = []\n",
    "for root, dirs, files in os.walk('./amass_data'):\n",
    "    if root == \"./amass_data\":\n",
    "        continue\n",
    "#     print(root, dirs, files)\n",
    "#     for folder in dirs:\n",
    "#         folders.append(os.path.join(root, folder))\n",
    "    folders.append(root)\n",
    "    for name in files:\n",
    "        dataset_name = root.split('/')[2]\n",
    "        if dataset_name not in dataset_names:\n",
    "            dataset_names.append(dataset_name)\n",
    "        paths.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = './pose_data'\n",
    "save_folders = [folder.replace('./amass_data', './pose_data') for folder in folders]\n",
    "for folder in save_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "group_path = [[path for path in paths if name in path] for name in dataset_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_matrix = np.array([[1.0, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 1.0],\n",
    "                            [0.0, 1.0, 0.0]])\n",
    "ex_fps = 20\n",
    "def amass_to_pose(src_path, save_path):\n",
    "    bdata = np.load(src_path, allow_pickle=True).item()\n",
    "    fps = 30\n",
    "\n",
    "    if bdata['gender'] == 'male':\n",
    "        bm = male_bm\n",
    "    elif bdata['gender'] == 'female':\n",
    "        bm = female_bm\n",
    "    else:\n",
    "        bm = neutral_bm\n",
    "    down_sample = int(fps / ex_fps)\n",
    "#     print(frame_number)\n",
    "#     print(fps)\n",
    "\n",
    "    source_bdata_poses = bdata['motion_source']['poses'][::down_sample,...]\n",
    "    source_bdata_trans = bdata['motion_source']['trans'][::down_sample,...]\n",
    "    source_body_parms = {\n",
    "            'root_orient': torch.Tensor(source_bdata_poses[:, :3]).to(comp_device),\n",
    "            'pose_body': torch.Tensor(source_bdata_poses[:, 3:66]).to(comp_device),\n",
    "            'pose_hand': torch.Tensor(source_bdata_poses[:, 66:]).to(comp_device),\n",
    "            'trans': torch.Tensor(source_bdata_trans).to(comp_device),\n",
    "            'betas': torch.Tensor(np.repeat(bdata['betas'][:num_betas].unsqueeze(0), repeats=len(source_bdata_trans), axis=0)).to(comp_device),\n",
    "        }\n",
    "    # print(\">>>>\")\n",
    "    # print(source_body_parms['root_orient'].shape)\n",
    "    # print(source_body_parms['pose_body'].shape)\n",
    "    # print(source_body_parms['pose_hand'].shape)\n",
    "    # print(source_body_parms['trans'].shape)\n",
    "    # print(source_body_parms['betas'].shape)\n",
    "    # print(\">>>>\")\n",
    "    with torch.no_grad():\n",
    "        source_body = bm(**source_body_parms)\n",
    "    source_pose_seq_np = source_body.Jtr.detach().cpu().numpy()\n",
    "    source_pose_seq_np_n = np.dot(source_pose_seq_np, trans_matrix)\n",
    "    source_pose_seq_np_n[..., 0] *= -1\n",
    "    \n",
    "    target_bdata_poses = bdata['motion_target']['poses'][::down_sample,...]\n",
    "    target_bdata_trans = bdata['motion_target']['trans'][::down_sample,...]\n",
    "    target_body_parms = {\n",
    "            'root_orient': torch.Tensor(target_bdata_poses[:, :3]).to(comp_device),\n",
    "            'pose_body': torch.Tensor(target_bdata_poses[:, 3:66]).to(comp_device),\n",
    "            'pose_hand': torch.Tensor(target_bdata_poses[:, 66:]).to(comp_device),\n",
    "            'trans': torch.Tensor(target_bdata_trans).to(comp_device),\n",
    "            'betas': torch.Tensor(np.repeat(bdata['betas'][:num_betas].unsqueeze(0), repeats=len(target_bdata_trans), axis=0)).to(comp_device),\n",
    "        }\n",
    "    with torch.no_grad():\n",
    "        target_body = bm(**target_body_parms)\n",
    "    target_pose_seq_np = target_body.Jtr.detach().cpu().numpy()\n",
    "    target_pose_seq_np_n = np.dot(target_pose_seq_np, trans_matrix)\n",
    "    target_pose_seq_np_n[..., 0] *= -1\n",
    "\n",
    "    pose_data = {\n",
    "        'source': source_pose_seq_np_n,\n",
    "        'target': target_pose_seq_np_n\n",
    "    }\n",
    "    \n",
    "    np.save(save_path, pose_data)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_path = group_path\n",
    "all_count = sum([len(paths) for paths in group_path])\n",
    "cur_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a few hours for all datasets, here we take one dataset as an example\n",
    "\n",
    "To accelerate the process, you could run multiple scripts like this at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: texts: 100%|██████████| 6730/6730 [00:00<00:00, 4509932.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 0): 6730/13460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: motion: 100%|██████████| 6730/6730 [00:30<00:00, 223.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 30): 13460/13460\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for paths in group_path:\n",
    "    dataset_name = paths[0].split('/')[2]\n",
    "    pbar = tqdm(paths)\n",
    "    pbar.set_description('Processing: %s'%dataset_name)\n",
    "    fps = 0\n",
    "    for path in pbar:\n",
    "        save_path = path.replace('./amass_data', './pose_data')\n",
    "        if save_path[-3:] == 'txt':\n",
    "            continue\n",
    "        save_path = save_path[:-3] + 'npy'\n",
    "        fps = amass_to_pose(path, save_path)\n",
    "        \n",
    "    cur_count += len(paths)\n",
    "    print('Processed / All (fps %d): %d/%d'% (fps, cur_count, all_count) )\n",
    "    time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfmotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
